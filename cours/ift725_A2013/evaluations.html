<!DOCTYPE html >
<html >
  <head>
    <title>Hugo Larochelle</title>
    <meta http-equiv="content-type" content="text/html; charset=iso-8859-1" />
    <link rel="stylesheet"
          href="http://fonts.googleapis.com/css?family=Droid+Sans:regular,bold"
          type="text/css" />
    <link rel="stylesheet" href="../../css/2.css" type="text/css" media="screen,projection" />

  </head>
  
  <body>

    <div id="wrapper">
      <div id="innerwrapper">

	<div id="header">
      <div id="header-text">
	    Hugo Larochelle
	  <!-- <h1 id="header-right"></h1>-->
	    <ul id="nav">
	      
	      <li><a href="../../index_fr.html" accesskey="a"><em>A</em>ccueil</a></li>
	      
	      <li><a href="../../publications_fr.html" accesskey="p"><em>P</em>ublications</a></li>

	      <li><a href="../../university_fr.html" accesskey="u" class="active"><em>U</em>niversité</a></li>

	      <li><a href="../../links_fr.html" accesskey="l"><em>L</em>iens</a></li>

	    </ul>
	  </div>
	  </div>
	  <div id="sidebar">
	    <h2>IFT 725 <small>(Automne 2013)</small></h2>
	    <table id="nav" cellpadding="0" cellspacing="8" width="120" >
	      <tr><td><a href="description.html">Description</a></td></tr>
	      <tr><td><a href="contenu.html">Contenu</a></td></tr>
	      <tr><td  class="active"><a href="evaluations.html">Évaluations</a></td></tr>
	    </table>
	    <h2>Annonces</h2>
	    <b>[06/01/2014]</b><br>
	    Notes finales du cours disponibles.</b><br><br>
	    <b>[06/01/2014]</b><br>
	    Notes des projets disponibles.</b><br><br>
	    <b>[13/12/2013]</b><br>
	    Notes des présentations disponibles.</b><br><br>
	    <b>[14/11/2013]</b><br>
	    Notes du devoir 3 disponibles.</b><br><br>
	    <b>[23/10/2013]</b><br>
	    Notes du devoir 2 disponibles.</b><br><br>
	    <b>[07/10/2013]</b><br>
	    Notes du devoir 1 disponibles.</b><br><br>
	    <b>[14/08/2013]</b><br>
	    Bienvenue au cours IFT 725!
	  </div>
	  
	  <!--
	  <div id="sidebarright">
	  </div>
	  -->

	  <div id="contentnorightbar">
	    <h2> Participation au forum (10 points)</h2> 
        Tout au long de
        la session, un forum de discussion est mis à la disposition
        des étudiants. À chaque semaine, l'étudiant devra y
        participer, en y publiant au moins un message. Ce message peut
        être une question liée à la matière de la semaine ou une réponse
        à la question d'un autre étudiant.
        <br><br>
        Un compte-rendu de la participation de chaque étudiant pour chaque
        semaine est disponible <a href="forum/participation_forum.txt">ici</a>.

	    <h2> Devoirs (devoirs 1 et 2 = 14 points, devoir 3 = 18 points)</h2>

	    <p> Pour toute question concernant les devoirs, n'hésitez pas à poser une question
	    sur le <a href="https://groups.google.com/forum/?fromgroups#!forum/ift-725-a2013">forum de discussion</a> du cours!
	      </p>

	    <table cellspacing="0" >
	      <tr bgcolor="#FD9842">
		<td width="10%"><b>Devoir</b></td> 
		<td width="60%"><b>Thème</b></td>
		<td width="15%"><b>Date de remise</b></td>
		<td width="15% align="right""><b>Notes</b></td>
	      </tr>
	      
	      <tr>
		<td >1</td> 
		<td><a href="devoir_1/devoir_1.pdf">Réseau de neurones à propagation avant</a> [<a href="devoir_1/devoir_1_en.pdf">EN</a>]<br><br>
          Fichiers nécessaires:
          <ul>
            <li> <a href="devoir_1/nnet.py">nnet.py</a><br>
            <li> <a href="devoir_1/run_nnet.py">run_nnet.py</a><br>
            <li> <a href="devoir_1/run_verify_gradients.py">run_verify_gradients.py</a>
          </ul><br>
        </td>
		<td>23 septembre</td>
        <td>[<a href="devoir_1/notes.txt">individuelles</a>] <br> [<a href="devoir_1/histogrammes_notes.png">histogrammes</a>]</td>
	      </tr>
	      
	      <tr bgcolor="#EEE">
		<td >2</td> 
		<td><a href="devoir_2/devoir_2.pdf">Champs markovien conditionnel</a> [<a href="devoir_2/devoir_2_en.pdf">EN</a>]<br><br>
          Fichiers nécessaires:
          <ul>
            <li> <a href="devoir_2/crf.py">crf.py</a><br>
            <li> <a href="devoir_2/run_crf.py">run_crf.py</a><br>
            <li> <a href="devoir_2/run_verify_gradients.py">run_verify_gradients.py</a>
            <li> <a href="devoir_2/ocr_letters_sequential.py">ocr_letters_sequential.py</a>
            <li> <a href="devoir_2/download_ocr_letters_sequential.py">download_ocr_letters_sequential.py</a>
          </ul><br>
        </td>
		<td>14 octobre </td> 
        <td>[<a href="devoir_2/notes.txt">individuelles</a>] <br> [<a href="devoir_2/histogrammes_notes.png">histogrammes</a>]</td>
	      </tr>
	      
	      <tr               >
		<td >3</td> 
		<td><a href="devoir_3/devoir_3.pdf">Machine de Boltzmann restreintes, autoencodeurs et réseaux profonds</a> [<a href="devoir_3/devoir_3_en.pdf">EN</a>]<br><br>
          Fichiers nécessaires:
          <ul>
            <li> <a href="devoir_3/nnet.py">nnet.py</a><br>
            <li> <a href="devoir_3/rbm.py">rbm.py</a><br>
            <li> <a href="devoir_3/run_show_filters_rbm.py">run_show_filters_rbm.py</a><br>
            <li> <a href="devoir_3/rbm_filters.pdf">rbm_filters.pdf</a>
            <li> <a href="devoir_3/run_stacked_rbms_nnet.py">run_stacked_rbms_nnet.py</a><br>
            <li> <a href="devoir_3/autoencoder.py">autoencoder.py</a><br>
            <li> <a href="devoir_3/run_show_filters_autoencoder.py">run_show_filters_autoencoder.py</a><br>
            <li> <a href="devoir_3/autoencoder_filters.pdf">autoencoder_filters.pdf</a>
            <li> <a href="devoir_3/run_stacked_autoencoders_nnet.py">run_stacked_autoencoders_nnet.py</a><br>
            <li> <a href="devoir_1/rapport.pdf">exemple de rapport</a>
          </ul><br>
        </td>
		<td>11 novembre </td>
        <td>[<a href="devoir_3/notes.txt">individuelles</a>] <br> [<a href="devoir_3/histogrammes_notes.png">histogrammes</a>]</td>
	      </tr>
	    </table>
	    
	    <h2> Projet d'application d'un réseau de neurones (30 points)</h2>

	    En plus des 3 devoirs, l'étudiant doit également proposer
	    et accomplir un projet d'application d'un réseau de
	    neurones.  
	    La définition du projet doit être faite en concertation
	    avec le professeur. Un exemple de
	    projet pourrait être la reproduction de certains résultats
	    d'un article scientifique.  Un autre exemple serait
	    l'application d'un réseau de neurones à un problème lié au
	    thème de recherche de l'étudiant. 
	    <br><br>
	    Une proposition de projet 
	    répondant aux questions suivantes doit d'abord être remise:
	    <br><br>
	    <ul>
	      <li> Quel réseau de neurones sera utilisé (inclure
		une courte description ou un référence vers un article
		scientifique) ?
          <li> Qu'est-ce qui sera implémenté par l'étudiant et quel
            code sera plutôt emprunté d'ailleurs (par exemple du code obtenu du web) ?
	      <li> Quelles expériences seront exécutées et avec quelle
            méthode de référence (<i>baseline</i>) seront faites les
            comparaisons (la méthode de référence peut être une méthode
            très simple) ?
	    </ul>
	    <br>
	    La proposition de projet 
	    doit être remise <b>au plus tard le 18 novembre.</b>
	    <br><br>
	    Le projet devra également faire l'objet d'un rapport final,
	    devant être <b>remis au plus tard le 18 décembre</b>. Le
	    rapport devra présenter l'approche implémentée ainsi
	    que les résultats obtenus. Dans la mesure du possible, le projet doit être implémenté
	    en Python et utiliser la libraire 
	    <a href="http://www.dmi.usherb.ca/~larocheh/mlpython/">MLPython</a>.
	    Le code utilisé devra être remis.
	    <br><br>
        Plus de détails sur la grille d'évaluation qui sera utilisée lors
        de la correction sont disponibles <a href="projet/projet.pdf">ici</a> [<a href="projet/projet_en.pdf">EN</a>].
        <br><br>

        <b>Les notes des projets sont <a href="projet/notes.txt">ici</a> [<a href="projet/histogrammes_notes.png">histrogrammes</a>].</b>
        <br><br>
	    <h2> Présentation d'un article scientifique (14 points)</h2>

	    À la fin de la session, chaque étudiant doit faire une
	    présentation orale suite à la lecture d'un article scientifique
	    lié aux réseaux de neurones.
	    La présentation doit durer 20 minutes et sera suivie d'une
	    période de questions de 5 minutes. 
	    <br><br>
	    
	    L'étudiant peut choisir lui-même l'article à présenter (en
	    concertation avec le professeur) ou il peut le choisir
	    parmi les lectures suggérées de la section <b>Contenu</b> 
	    ou encore parmi les articles suivants:
	    
	    <br><br>
	    <ul id="contenucours">
	      <li> <a href="http://www.dmi.usherb.ca/~larocheh/publications/aistats2011_nade.pdf">
		  <i>The Neural Autoregressive Distribution Estimator</i></a> de
		<a href="http://www.dmi.usherb.ca/~larocheh/">Hugo Larochelle</a> et
		<a href="http://homepages.inf.ed.ac.uk/imurray2/">Iain Murray</a> [<a href="http://videolectures.net/aistats2011_larochelle_neural/">video</a>]
	      <li> <a href="http://books.nips.cc/papers/files/nips24/NIPS2011_1240.pdf">
		  <i>The Manifold Tangent Classifier</i></a>
		de <a href="http://www-etud.iro.umontreal.ca/~rifaisal/">Salah Rifai</a>,
		<a href="http://ynd.github.com/">Yann Dauphin</a>,
		<a href="http://www.iro.umontreal.ca/~vincentp/">Pascal Vincent</a>,
		<a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html">Yoshua Bengio</a>
		et Xavier Muller [<a href="http://videolectures.net/nips2011_dauphin_manifold/">video</a>]
	      <li> <a href="http://www6.in.tum.de/Main/Publications/Graves2006a.pdf">
		  <i>Connectionist Temporal Classification: Labelling Unsegmented
		    Sequence Data with Recurrent Neural Networks</i></a> de
		<a href="http://www6.in.tum.de/Main/Graves">Alex Graves</a>,
		<a href="http://www.idsia.ch/~santiago/publications.html">Santiago Fernández</a>,
		<a href="http://www.idsia.ch/~tino/">Faustino Gomez</a>
		et <a href="http://www.idsia.ch/~juergen/">Jürgen Schmidhuber</a>
	      <li> <a href="http://www.uoguelph.ca/~gwtaylor/publications/jmlr2011/taylor11a.pdf">
		  <i>Two Distributed-State Models For Generating High-Dimensional Time Series</i></a>
		de <a href="http://www.uoguelph.ca/~gwtaylor/">Graham Taylor</a>,
		<a href="http://www.cs.toronto.edu/~hinton/">Geoffrey Hinton</a> et
		<a href="http://www.cs.nyu.edu/~roweis/">Sam Roweis</a>
	      <li> <a href="http://www.uoguelph.ca/~gwtaylor/publications/cvpr2010/gwtaylor_cvpr2010.pdf">
		  <i>Dynamical Binary Latent Variable Models for 3D Human Pose Tracking</i></a>
		de <a href="http://www.uoguelph.ca/~gwtaylor/">Graham Taylor</a>,
		<a href="http://www.cs.brown.edu/~ls/">Leonid Sigal</a>,
		<a href="http://www.cs.toronto.edu/~fleet/">David Fleet</a> et
		<a href="http://www.cs.toronto.edu/~hinton/">Geoffrey Hinton</a>
	      <li> <a href="http://research.microsoft.com/pubs/153169/cd-dnn-hmm-swb-interspeech2011-pub.pdf"><i>
		    Conversational Speech Transcription Using Context-Dependent Deep Neural Networks</i></a>
		de <a href="http://research.microsoft.com/en-us/people/fseide/">Frank Seide</a>,
		Gang Li et 
		<a href="http://research.microsoft.com/en-us/people/dongyu/">Dong Yu</a> [<a href="http://techtalks.tv/talks/conversational-speech-transcription-using-context-dependent-deep-neural-networks/57462/">video</a>]
	      <li> <a href="http://ai.stanford.edu/~quocle/faces_full.pdf"><i>
		    Building high-level features using large scale unsupervised learning</i></a>
		de <a href="http://ai.stanford.edu/~quocle/">Quoc Le</a>,
		<a href="http://www.cs.toronto.edu/~ranzato/">Marc'Aurelio Ranzato</a>,
		Rajat Monga,
		Matthieu Devin,
		Kai Chen,
		Greg Corrado,
		<a href="http://research.google.com/people/jeff/">Jeff Dean</a>
		et <a href="http://ai.stanford.edu/~ang/">Andrew Ng</a> [<a href="http://techtalks.tv/talks/building-high-level-features-using-large-scale-unsupervised-learning/57421/">video</a>]
	      <li> <a href="http://arxiv.org/pdf/1206.6392.pdf"><i>
		    Modeling Temporal Dependencies in High-Dimensional Sequences: 
		    Application to Polyphonic Music Generation and Transcription</i></a>
		de Nicolas Boulanger-Lewandowski,
		<a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html">Yoshua Bengio</a>
		et <a href="http://www.iro.umontreal.ca/~vincentp/">Pascal Vincent</a> [<a href="http://techtalks.tv/talks/modeling-temporal-dependencies-in-high-dimensional-sequences-application-to-polyphonic-music-generat../57449/">video</a>]
	      <li> <a href="http://www.utstat.toronto.edu/~rsalakhu/papers/nonlinnca.pdf">
		  <i>Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure</i></a>
		de <a href="http://www.utstat.toronto.edu/~rsalakhu">Ruslan Salakhutdinov</a>
			  et <a href="http://www.cs.toronto.edu/~hinton/">Geoffrey Hinton</a>
	    </ul>
	    <br>

	    L'étudiant doit confirmer le choix de son article
	    auprès du professeur <b>avant le 18 novembre 2013</b>.<br><br>
        <a name="horaire_presentations"><h3>Horaire des présentations</h3></a>
	    <br>

	    <table cellspacing="0" >
	      <tr bgcolor="#FD9842">
		    <td width="40%"><b>VE 29/11</b></td> 
            <td width="60%"><b>Article présenté</b></td> 
          <tr><td><b>13h30:</b> Étienne St-Onge </td><td> <a href="https://37ad672a-a-62cb3a1a-s-sites.googlegroups.com/site/machinelearningandrobotics/publications/learch-autonomous-robots-2009.pdf?attachauth=ANoY7crWtkAjgE3f1Gxdk4rFDWUziYMakksKxLH0Z-0aHxNRb_QqZM32RFTriAptAeOdbVr4NZ1UBh9JMjHjrWExYNnsNQ69V9a_Epfl_VtouAmSWZU6iGt_2LwP2pFc0i-WIp74N_nnAfL1DoChrVOiawPLBqppLbleMY8O-DKze6ZDTpWjieREi68DW88Sxr2PGwLoQb1RSP3gOTrMiaaDGAYqqfn6tExdcjxH1KEPmGzHIgrNtYyrr6zfOSX3GQqGxnt14F039FPOsJhmTlyklnWSxjtQgw%3D%3D&attredirects=0">
		        <i>Learning to Search: Functional Gradient Techniques for Imitation Learning</i></a></td></tr>
          <tr bgcolor="#EEE"><td><b>13h55:</b> Ahmed Ladhar </td><td><a href="http://www.cs.toronto.edu/~norouzi/research/papers/min_loss_hash.pdf">
		  <i>Minimal Loss Hashing for Compact Binary Codes</i></a> </td></tr>
          <tr><td><b>14h30:</b> Alex Boulanger </td><td> <a href="http://machinelearning.wustl.edu/mlpapers/paper_files/GersSS02.pdf">
		        <i>Learning Precise Timing with LSTM Recurrent Networks</i></a></td></tr>
          <tr bgcolor="#EEE"><td><b>14h55:</b> Félix-Antoine Ouellet</td><td><a href="http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf">
		  <i>Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank</i></a> </td></tr>
          <tr><td><b>15h30:</b> Francis Bisson</td><td> <a href="http://cs.stanford.edu/~quocle/LeZouYeungNg11.pdf">
		        <i>Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis</i></a></td></tr>
          <tr bgcolor="#EEE"><td><b>15h55:</b> Éric Néron</td><td><a href="http://arxiv.org/pdf/1306.2795v1.pdf">
		  <i>Recurrent Convolutional Neural Networks for Scene Parsing</i></a> </td></tr>
        </table>
<br>
        <br>
        <b>Les notes des présentations sont <a href="presentation/notes.txt">ici</a> [<a href="presentation/histogrammes_notes.png">histrogramme</a>].</b>

	    <h2> Notes finales </h2>
	    
	    Les <a href="notes_finales.txt">notes finales</a> du cours
	    sont maintenant
	    disponibles. Les <a href="histogrammes_notes_finales.png">histogrammes</a>
	    de notes pour chaque évaluation peuvent aussi être
	    consultés.
	  </div>
	  
	  <div id="footer">
	  </div>
	  
	</div>
      </div>


    </body>
  </html>
