<!DOCTYPE html >
<html >
  <head>
    <title>Hugo Larochelle</title>
    <meta http-equiv="content-type" content="text/html; charset=iso-8859-1" />
    <link rel="stylesheet" href="../../css/1.css" type="text/css" media="screen,projection" />

  </head>
  
  <body>

    <div id="wrapper">
      <div id="innerwrapper">

	<div id="header">
	  <font color="#FFFFFF">
	    <font face="Copperplate" size=8>Hugo Larochelle</font>
	    <br> http://www.dmi.usherb.ca/~larocheh/
	  </font>
	  <!-- <h1 id="header-right"></h1>-->
	    <ul id="nav">
	      
	      <li><a href="../../index_fr.html" accesskey="a"><em>A</em>ccueil</a></li>
	      
	      <li><a href="../../publications_fr.html" accesskey="p"><em>P</em>ublications</a></li>

	      <li><a href="../../university_fr.html" accesskey="u" class="active"><em>U</em>niversité</a></li>

	      <li><a href="../../links_fr.html" accesskey="l"><em>L</em>iens</a></li>

	    </ul>
	  </div>
	  
	  <div id="sidebar">
	    <h2>IFT 725 <small>(Automne 2012)</small></h2>
	    <table id="nav" cellpadding="0" cellspacing="2" >
	      <tr><td><a href="description.html">Description</a></td></tr>
	      <tr><td><a href="contenu.html">Contenu</a></td></tr>
	      <tr><td class="active"><a href="evaluations.html">Évaluations</a></td></tr>
	    </table>
	    <h2>Annonces</h2>
	    <b>[03/12/2012]</b><br>
	    Les notes des présentations sont disponibles.<br><br>

	    <b>[25/11/2012]</b><br>
	    Les notes du devoir 3 sont disponibles.<br><br>

	    <b>[29/10/2012]</b><br>
	    Les notes du devoir 2 sont disponibles.<br><br>

	    <b>[12/10/2012]</b><br>
	    Le devoir 3 est disponible.<br><br>

	    <b>[07/10/2012]</b><br>
	    Les notes du devoir 1 sont disponibles.<br><br>

	    <b>[21/09/2012]</b><br>
	    Le devoir 2 est disponible.<br><br>

        <b>[31/08/2012]</b><br>
        Les prochains cours auront lieu
        les vendredis, de 8h30 à 11h30, au D4-1023<br><br>

	    <b>[28/08/2012]</b><br>
	    Premier cours: <br>31 août, 9h-12h, au D4-2024.<br><br>

	    <b>[27/08/2012]</b><br>
	    Le devoir 1 est disponible.<br><br>

	    <b>[20/08/2012]</b><br>
	    La séance d'information sera
	    le <b>27 août, à 13h00, au D4-2025.</b><br><br>

	    <b>[13/08/2012]</b><br>
	    Bienvenue au cours IFT 725!
	  </div>
	  
	  <!--
	  <div id="sidebarright">
	  </div>
	  -->

	  <div id="contentnorightbar">
	    <h2> Devoirs (18 points chacun)</h2>

	    <p> Pour toute question concernant les devoirs, n'hésitez pas à poser une question
	    sur le <a href="https://groups.google.com/forum/?fromgroups#!forum/ift-725-a2012">forum de discussion</a> du cours!
	      </p>

	    <table cellspacing="0" >
	      <tr bgcolor="#666">
		<td width="10%"><font color="#FFF"><b>Devoir</b></font></td> 
		<td width="15%"><font color="#FFF"><b>Énoncé donné le</b></font></td> 
		<td width="45%"><font color="#FFF"><b>Thème</b></font> </td>
		<td width="15%"><font color="#FFF"><b>Date de remise</b></font></td>
		<td width="25%"><font color="#FFF"><b>Notes</b></font></td>
	      </tr>
	      
	      <tr               >
		<td >1</td> 
		<td>27 août </td> 
		<td><a href="devoir_1/devoir_1.pdf">Réseau de neurones à propagation avant</a> [<a href="devoir_1/devoir_1_en.pdf">EN</a>]<br><br>
          Fichiers nécessaires:
          <ul>
            <li> <a href="devoir_1/nnet.py">nnet.py</a><br>
            <li> <a href="devoir_1/run_nnet.py">run_nnet.py</a><br>
            <li> <a href="devoir_1/run_verify_gradients.py">run_verify_gradients.py</a>
          </ul><br>
        </td>
		<td>21 septembre</td>
        <td>[<a href="devoir_1/notes.txt">individuelles</a>] <br> [<a href="devoir_1/histogrammes_notes.png">histogrammes</a>] <br><br>[<a href="devoir_1/rapport.pdf">rapport</a>]</td>
	      </tr>
	      
	      <tr bgcolor="#EEE">
		<td >2</td> 
		<td>21 septembre</td> 
		<td><a href="devoir_2/devoir_2.pdf">Champs markovien conditionnel</a> [<a href="devoir_2/devoir_2_en.pdf">EN</a>]<br><br>
          Fichiers nécessaires:
          <ul>
            <li> <a href="devoir_2/crf.py">crf.py</a><br>
            <li> <a href="devoir_2/run_crf.py">run_crf.py</a><br>
            <li> <a href="devoir_2/run_verify_gradients.py">run_verify_gradients.py</a>
            <li> <a href="devoir_2/ocr_letters_sequential.py">ocr_letters_sequential.py</a>
            <li> <a href="devoir_2/download_ocr_letters_sequential.py">download_ocr_letters_sequential.py</a>
          </ul><br>
        </td>
		<td>12 octobre </td> 
        <td>[<a href="devoir_2/notes.txt">individuelles</a>] <br> [<a href="devoir_2/histogrammes_notes.png">histogrammes</a>]</td>
	      </tr>
	      
	      <tr               >
		<td >3</td> 
		<td>12 octobre</td> 
		<td><a href="devoir_3/devoir_3.pdf">Machine de Boltzmann restreintes, autoencodeurs et réseaux profonds</a> [<a href="devoir_3/devoir_3_en.pdf">EN</a>]<br><br>
          Fichiers nécessaires:
          <ul>
            <li> <a href="devoir_3/nnet.py">nnet.py</a><br>
            <li> <a href="devoir_3/rbm.py">rbm.py</a><br>
            <li> <a href="devoir_3/run_show_filters_rbm.py">run_show_filters_rbm.py</a><br>
            <li> <a href="devoir_3/rbm_filters.pdf">rbm_filters.pdf</a>
            <li> <a href="devoir_3/run_stacked_rbms_nnet.py">run_stacked_rbms_nnet.py</a><br>
            <li> <a href="devoir_3/autoencoder.py">autoencoder.py</a><br>
            <li> <a href="devoir_3/run_show_filters_autoencoder.py">run_show_filters_autoencoder.py</a><br>
            <li> <a href="devoir_3/autoencoder_filters.pdf">autoencoder_filters.pdf</a>
            <li> <a href="devoir_3/run_stacked_autoencoders_nnet.py">run_stacked_autoencoders_nnet.py</a><br>
          </ul><br>
        </td>
		<td>9 novembre </td>
        <td>[<a href="devoir_3/notes.txt">individuelles</a>] <br> [<a href="devoir_3/histogrammes_notes.png">histogrammes</a>]</td>
	      </tr>
	    </table>
	    
	    <h2> Projet d'application d'un réseau de neurones (30 points)</h2>

	    En plus des 3 devoirs, l'étudiant doit également proposer
	    et accomplir un projet d'application d'un réseau de
	    neurones.  
	    La définition du projet doit être faite en concertation
	    avec le professeur. Un exemple de
	    projet pourrait être la reproduction de certains résultats
	    d'un article scientifique.  Un autre exemple serait
	    l'application d'un réseau de neurones à un problème lié au
	    thème de recherche de l'étudiant. 
	    <br><br>
	    Une proposition de projet 
	    répondant aux questions suivantes doit d'abord être remise:
	    <br><br>
	    <ul>
	      <li> Quel réseau de neurones sera utilisé (inclure
		une courte description ou un référence vers un article
		scientifique) ?
          <li> Qu'est-ce qui sera implémenté par l'étudiant et quel
            code sera plutôt emprunté d'ailleurs (par exemple du code obtenu du web) ?
	      <li> Quelles expériences seront exécutées et avec quelle
            méthode de référence (<i>baseline</i>) seront faites les
            comparaisons (la méthode de référence peut être une méthode
            très simple) ?
	    </ul>
	    <br>
	    La proposition de projet 
	    doit être remise <b>au plus tard le 16 novembre.</b>
	    <br><br>
	    Le projet devra également faire l'objet d'un rapport final,
	    devant être <b>remis au plus tard le 14 décembre</b>. Le
	    rapport devra présenter l'approche implémentée ainsi
	    que les résultats obtenus. Dans la mesure du possible, le projet doit être implémenté
	    en Python et utiliser la libraire 
	    <a href="http://www.dmi.usherb.ca/~larocheh/mlpython/">MLPython</a>.
	    Le code utilisé devra être remis.
	    <br><br>
        Plus de détails sur la grille d'évaluation qui sera utilisée lors
        de la correction sont disponibles <a href="projet/projet.pdf">ici</a> [<a href="projet/projet_en.pdf">EN</a>].
        <br><br>
        <b>Les notes des projets sont <a href="projet/notes.txt">ici</a> [<a href="projet/histogramme_notes.png">histrogramme</a>].</b>
        <br><br>
	    <h2> Présentation d'un article scientifique (16 points)</h2>

	    À la fin de la session, chaque étudiant doit faire une
	    présentation orale suite à la lecture d'un article scientifique
	    lié aux réseaux de neurones.
	    La présentation doit durer 20 minutes et sera suivie d'une
	    période de questions de 5 minutes. 
	    <br><br>
	    
	    L'étudiant peut choisir lui-même l'article à présenter (en
	    concertation avec le professeur) ou il peut le choisir
	    parmi les lectures suggérées de la section <b>Contenu</b> 
	    ou encore parmi les articles suivants:
	    
	    <br><br>
	    <ul id="contenucours">
	      <li> <a href="http://www.dmi.usherb.ca/~larocheh/publications/aistats2011_nade.pdf">
		  <i>The Neural Autoregressive Distribution Estimator</i></a> de
		<a href="http://www.dmi.usherb.ca/~larocheh/">Hugo Larochelle</a> et
		<a href="http://homepages.inf.ed.ac.uk/imurray2/">Iain Murray</a> [<a href="http://videolectures.net/aistats2011_larochelle_neural/">video</a>]
	      <li> <a href="http://books.nips.cc/papers/files/nips24/NIPS2011_1240.pdf">
		  <i>The Manifold Tangent Classifier</i></a>
		de <a href="http://www-etud.iro.umontreal.ca/~rifaisal/">Salah Rifai</a>,
		<a href="http://ynd.github.com/">Yann Dauphin</a>,
		<a href="http://www.iro.umontreal.ca/~vincentp/">Pascal Vincent</a>,
		<a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html">Yoshua Bengio</a>
		et Xavier Muller [<a href="http://videolectures.net/nips2011_dauphin_manifold/">video</a>]
	      <li> <a href="http://www6.in.tum.de/Main/Publications/Graves2006a.pdf">
		  <i>Connectionist Temporal Classification: Labelling Unsegmented
		    Sequence Data with Recurrent Neural Networks</i></a> de
		<a href="http://www6.in.tum.de/Main/Graves">Alex Graves</a>,
		<a href="http://www.idsia.ch/~santiago/publications.html">Santiago Fernández</a>,
		<a href="http://www.idsia.ch/~tino/">Faustino Gomez</a>
		et <a href="http://www.idsia.ch/~juergen/">Jürgen Schmidhuber</a>
	      <li> <a href="http://www.uoguelph.ca/~gwtaylor/publications/jmlr2011/taylor11a.pdf">
		  <i>Two Distributed-State Models For Generating High-Dimensional Time Series</i></a>
		de <a href="http://www.uoguelph.ca/~gwtaylor/">Graham Taylor</a>,
		<a href="http://www.cs.toronto.edu/~hinton/">Geoffrey Hinton</a> et
		<a href="http://www.cs.nyu.edu/~roweis/">Sam Roweis</a>
	      <li> <a href="http://www.uoguelph.ca/~gwtaylor/publications/cvpr2010/gwtaylor_cvpr2010.pdf">
		  <i>Dynamical Binary Latent Variable Models for 3D Human Pose Tracking</i></a>
		de <a href="http://www.uoguelph.ca/~gwtaylor/">Graham Taylor</a>,
		<a href="http://www.cs.brown.edu/~ls/">Leonid Sigal</a>,
		<a href="http://www.cs.toronto.edu/~fleet/">David Fleet</a> et
		<a href="http://www.cs.toronto.edu/~hinton/">Geoffrey Hinton</a>
	      <li> <a href="http://research.microsoft.com/pubs/153169/cd-dnn-hmm-swb-interspeech2011-pub.pdf"><i>
		    Conversational Speech Transcription Using Context-Dependent Deep Neural Networks</i></a>
		de <a href="http://research.microsoft.com/en-us/people/fseide/">Frank Seide</a>,
		Gang Li et 
		<a href="http://research.microsoft.com/en-us/people/dongyu/">Dong Yu</a> [<a href="http://techtalks.tv/talks/conversational-speech-transcription-using-context-dependent-deep-neural-networks/57462/">video</a>]
	      <li> <a href="http://ai.stanford.edu/~quocle/faces_full.pdf"><i>
		    Building high-level features using large scale unsupervised learning</i></a>
		de <a href="http://ai.stanford.edu/~quocle/">Quoc Le</a>,
		<a href="http://www.cs.toronto.edu/~ranzato/">Marc'Aurelio Ranzato</a>,
		Rajat Monga,
		Matthieu Devin,
		Kai Chen,
		Greg Corrado,
		<a href="http://research.google.com/people/jeff/">Jeff Dean</a>
		et <a href="http://ai.stanford.edu/~ang/">Andrew Ng</a> [<a href="http://techtalks.tv/talks/building-high-level-features-using-large-scale-unsupervised-learning/57421/">video</a>]
	      <li> <a href="http://arxiv.org/pdf/1206.6392.pdf"><i>
		    Modeling Temporal Dependencies in High-Dimensional Sequences: 
		    Application to Polyphonic Music Generation and Transcription</i></a>
		de Nicolas Boulanger-Lewandowski,
		<a href="http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html">Yoshua Bengio</a>
		et <a href="http://www.iro.umontreal.ca/~vincentp/">Pascal Vincent</a> [<a href="http://techtalks.tv/talks/modeling-temporal-dependencies-in-high-dimensional-sequences-application-to-polyphonic-music-generat../57449/">video</a>]
	      <li> <a href="http://www.utstat.toronto.edu/~rsalakhu/papers/nonlinnca.pdf">
		  <i>Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure</i></a>
		de <a href="http://www.utstat.toronto.edu/~rsalakhu">Ruslan Salakhutdinov</a>
			  et <a href="http://www.cs.toronto.edu/~hinton/">Geoffrey Hinton</a>
	    </ul>
	    <br>

	    L'étudiant doit confirmer le choix de son article
	    auprès du professeur <b>avant le 16 novembre 2012</b>.<br><br>

        <a name="horaire_presentations"><h3>Horaire des présentations</h3></a>
	    <br>

	    <table cellspacing="0" >
	      <tr bgcolor="#666">
		    <td width="30%"><font color="#FFF"><b>VE 23/11</b></font></td> 
            <td width="70%"><font color="#FFF"><b>Article présenté</b></font></td> 
          <tr><td><b>8h30:</b> Cody Stoutenburg </td><td> <a href="http://www.utstat.toronto.edu/~rsalakhu/papers/nonlinnca.pdf">
		        <i>Learning a Nonlinear Embedding by Preserving Class Neighbourhood Structure</i></a></td></tr>
          <tr bgcolor="#EEE"><td><b>8h55:</b> Mathieu Germain</td><td><a href="http://www.dmi.usherb.ca/~larocheh/publications/aistats2011_nade.pdf">
		  <i>The Neural Autoregressive Distribution Estimator</i></a> </td></tr>
          <tr><td><b>9h30:</b> Stanislas Lauly </td><td>  <a href="http://www.dmi.usherb.ca/~larocheh/publications/nips_2012_camera_ready.pdf"><i>A Neural Autoregressive Topic Model</i></a></td></tr>
          <tr bgcolor="#EEE"><td><b>9h55:</b> Samuel St-Jean </td><td>  <a href="http://www.di.ens.fr/~jenatton/paper/HierarchicalDictionaryLearningICML2010.pdf"><i>Proximal Methods for Sparse Hierarchical Dictionary Learning</i></a></td></tr>
          <tr><td><b>10h30:</b> Mohammad Havaei </td><td>  <a href="http://books.nips.cc/papers/files/nips04/0895.pdf"><i>Tangent prop - A formalism for specifying selected invariances in an adaptive network</i></a></td></tr>
          <tr bgcolor="#EEE"><td><b>10h55:</b> Alexei Nordell</td><td> <a href="http://www.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf">
			    <i>An Analysis of Single-Layer Networks in Unsupervised Feature Learning</i></a> </td> </tr>
        </table>
<br>

	    <table cellspacing="0" >
	      <tr bgcolor="#666">
		    <td width="30%"><font color="#FFF"><b>VE 30/11</b></font></td> 
            <td width="70%"><font color="#FFF"><b>Article présenté</b></font></td> 
          <tr><td><b>8h30:</b> Adam Salvail-Bérard</td><td> <a href="http://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf "><i>Deep learning via Hessian-free optimization</i></a> </td></tr>
          <tr bgcolor="#EEE"><td><b>8h55:</b>  Emmanuelle Renauld</td><td> <a href="http://www.utstat.toronto.edu/~rsalakhu/papers/robm.pdf"><i>Robust Boltzmann Machines for Recognition and Denoising</i></a></td></tr>
          <tr><td><b>9h30:</b> Marc-Alexandre Côté</td><td> <a href="http://www.utstat.toronto.edu/~rsalakhu/papers/dbm.pdf"><i>Deep Boltzmann Machines</i></a></td></tr>
          <tr bgcolor="#EEE"><td><b>9h55:</b> Clément Proust</td><td> <a href="http://www.stanford.edu/~acoates/papers/coatesng_icml_2011.pdf"><i>
			      The Importance of Encoding Versus Training with Sparse Coding and Vector Quantization</i></a></td></tr>
          <tr><td><b>10h30:</b> Dayron Rizo </td><td>  <a href="http://ai.stanford.edu/~quocle/faces_full.pdf"><i>
		    Building high-level features using large scale unsupervised learning</i></a></td></tr>
          <tr bgcolor="#EEE"><td><b>10h55:</b> Ali Vashaee </td><td>  <a href="http://www.utstat.toronto.edu/~rsalakhu/papers/semantic_final.pdf">
			    <i>Semantic hashing</i></a></td></tr>
        </table>
        <br>
        <b>Les notes des présentations sont <a href="presentation/notes.txt">ici</a> [<a href="presentation/histogrammes_notes.png">histrogramme</a>].</b>
	    <h2> Notes finales </h2>
	    
	    Les <a href="notes_finales.txt">notes finales</a> du cours
	    sont maintenant
	    disponibles. Les <a href="histogrammes_notes_finales.png">histogrammes</a>
	    de notes pour chaque évaluation peuvent aussi être
	    consultés.
	  </div>
	  
	  <div id="footer">
	  </div>
	  
	</div>
      </div>


    </body>
  </html>
