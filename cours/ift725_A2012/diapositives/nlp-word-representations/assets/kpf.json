{"slideHeight":768,
"filename":"nlp-word-representations.key",
"navigatorEvents":[{"eventName":"Slide 1",
"eventIndex":0}
,{"eventName":"Slide 2",
"eventIndex":1}
,{"eventName":"Slide 3",
"eventIndex":2}
,{"eventName":"Slide 4",
"eventIndex":3}
,{"eventName":"Slide 5",
"eventIndex":4}
,{"eventName":"Slide 6",
"eventIndex":5}
,{"eventName":"Slide 7",
"eventIndex":6}
,{"eventName":"Slide 8",
"eventIndex":7}
,{"eventName":"Slide 9",
"eventIndex":8}
,{"eventName":"Slide 10",
"eventIndex":9}
,{"eventName":"Slide 11",
"eventIndex":10}
,{"eventName":"Slide 12",
"eventIndex":11}
,{"eventName":"Slide 13",
"eventIndex":12}
]
,
"textures":{"s2.b":{"url":"images-1/s2.b.jpeg",
"width":1024,
"height":768}
,
"s8.b":{"url":"images-1/s8.b.jpeg",
"width":1024,
"height":768}
,
"s12.b":{"url":"images-1/s12.b.jpeg",
"width":1024,
"height":768}
,
"s5.a":{"url":"images-1/s4.b.jpeg",
"width":1024,
"height":768}
,
"s3.b":{"url":"images-1/s3.b.jpeg",
"width":1024,
"height":768}
,
"s9.b":{"url":"images-1/s9.b.jpeg",
"width":1024,
"height":768}
,
"s12.a":{"url":"images-1/s11.b.jpeg",
"width":1024,
"height":768}
,
"s6.a":{"url":"images-1/s5.b.jpeg",
"width":1024,
"height":768}
,
"s10.b":{"url":"images-1/s10.b.jpeg",
"width":1024,
"height":768}
,
"s4.b":{"url":"images-1/s4.b.jpeg",
"width":1024,
"height":768}
,
"s1.a":{"url":"images-1/s1.a.jpeg",
"width":1024,
"height":768}
,
"s7.a":{"url":"images-1/s6.b.jpeg",
"width":1024,
"height":768}
,
"s10.a":{"url":"images-1/s9.b.jpeg",
"width":1024,
"height":768}
,
"s13.b":{"url":"images-1/s13.b.png",
"width":1024,
"height":768}
,
"s5.b":{"url":"images-1/s5.b.jpeg",
"width":1024,
"height":768}
,
"thumbnail":{"url":"images-1/thumbnail.jpeg",
"width":458,
"height":344}
,
"s2.a":{"url":"images-1/s1.b.jpeg",
"width":1024,
"height":768}
,
"s8.a":{"url":"images-1/s7.b.jpeg",
"width":1024,
"height":768}
,
"s13.a":{"url":"images-1/s12.b.jpeg",
"width":1024,
"height":768}
,
"s11.b":{"url":"images-1/s11.b.jpeg",
"width":1024,
"height":768}
,
"s6.b":{"url":"images-1/s6.b.jpeg",
"width":1024,
"height":768}
,
"s3.a":{"url":"images-1/s2.b.jpeg",
"width":1024,
"height":768}
,
"s9.a":{"url":"images-1/s8.b.jpeg",
"width":1024,
"height":768}
,
"s1.b":{"url":"images-1/s1.b.jpeg",
"width":1024,
"height":768}
,
"s7.b":{"url":"images-1/s7.b.jpeg",
"width":1024,
"height":768}
,
"s11.a":{"url":"images-1/s10.b.jpeg",
"width":1024,
"height":768}
,
"s4.a":{"url":"images-1/s3.b.jpeg",
"width":1024,
"height":768}
}
,
"title":"nlp-word-representations.key",
"minorVersion":4,
"timestamp":"2012-11-19 14:33:59",
"slideWidth":1024,
"eventTimelines":[{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s1.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s1.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s1.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s1.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s1.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s1.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":460,
"width":714,
"x":52,
"height":72}
,
"text":"Natural language processing:"}
,{"targetRectangle":{"y":532,
"width":539,
"x":52,
"height":72}
,
"text":"word representations"}
,{"targetRectangle":{"y":611,
"width":443,
"x":52,
"height":43}
,
"text":"IFT 725 - Réseaux neuronaux"}
,{"targetRectangle":{"y":457.3852,
"width":2.043051,
"x":21.10369,
"height":218.1459}
,
"text":""}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s2.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s2.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s2.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s2.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s2.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s2.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":62,
"width":942,
"x":41,
"height":68}
,
"text":"Natural Language Processing"}
,{"targetRectangle":{"y":148,
"width":654,
"x":32,
"height":63}
,
"text":"Topics: natural language processing (NLP)"}
,{"targetRectangle":{"y":210,
"width":922,
"x":56,
"height":105}
,
"text":"Natural language processing is concerned with tasks involving language data "}
,{"targetRectangle":{"y":314,
"width":341,
"x":86,
"height":51}
,
"text":"we will focus on text data NLP"}
,{"targetRectangle":{"y":364,
"width":787,
"x":86,
"height":83}
,
"text":"speech processing is also NLP, though it has its own dedicated research community"}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":496,
"width":932,
"x":56,
"height":105}
,
"text":"Much like for computer vision, we can design neural networks specifically adapted to the processing of text data"}
,{"targetRectangle":{"y":600,
"width":550,
"x":86,
"height":33}
,
"text":"main issue: text data is inherently high dimensional"}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s3.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s3.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s3.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s3.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s3.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s3.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":62,
"width":942,
"x":41,
"height":68}
,
"text":"Natural Language Processing"}
,{"targetRectangle":{"y":148,
"width":326,
"x":32,
"height":63}
,
"text":"Topics: tokenization"}
,{"targetRectangle":{"y":210,
"width":586,
"x":56,
"height":62}
,
"text":"Typical preprocessing steps of text data"}
,{"targetRectangle":{"y":271,
"width":628,
"x":86,
"height":51}
,
"text":"tokenize text (from a long string to a list of token strings)"}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":621,
"width":584,
"x":86,
"height":51}
,
"text":"for many datasets, this has already been done for you"}
,{"targetRectangle":{"y":671,
"width":890,
"x":86,
"height":65}
,
"text":"splitting into tokens based on spaces and separating punctuation is good enough in English or French"}
,{"targetRectangle":{"y":425,
"width":365,
"x":87.82471,
"height":56}
,
"text":"‘‘ He’s spending 7 days in San Francisco. ’’"}
,{"targetRectangle":{"y":397,
"width":100,
"x":488,
"height":100}
,
"text":""}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s4.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s4.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s4.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s4.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s4.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s4.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":62,
"width":942,
"x":41,
"height":68}
,
"text":"Natural Language Processing"}
,{"targetRectangle":{"y":148,
"width":353,
"x":32,
"height":63}
,
"text":"Topics: lemmatization"}
,{"targetRectangle":{"y":210,
"width":586,
"x":56,
"height":62}
,
"text":"Typical preprocessing steps of text data"}
,{"targetRectangle":{"y":271,
"width":468,
"x":86,
"height":51}
,
"text":"lemmatize tokens (put into standard form)"}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":621,
"width":796,
"x":86,
"height":51}
,
"text":"the specific lemmatization will depend on the problem we want to solve"}
,{"targetRectangle":{"y":671,
"width":716,
"x":116,
"height":29}
,
"text":"we can remove variations of words that are not relevant to the task at hand"}
,{"targetRectangle":{"y":397,
"width":100,
"x":488,
"height":100}
,
"text":""}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s5.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s5.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s5.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s5.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s5.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s5.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":62,
"width":942,
"x":41,
"height":68}
,
"text":"Natural Language Processing"}
,{"targetRectangle":{"y":148,
"width":306,
"x":32,
"height":63}
,
"text":"Topics: vocabulary"}
,{"targetRectangle":{"y":210,
"width":586,
"x":56,
"height":62}
,
"text":"Typical preprocessing steps of text data"}
,{"targetRectangle":{"y":271,
"width":793,
"x":86,
"height":83}
,
"text":"form vocabulary of words that maps lemmatized words to a unique ID \u2028(position of word in vocabulary)"}
,{"targetRectangle":{"y":353,
"width":860,
"x":86,
"height":51}
,
"text":"different criteria can be used to select which words are part of the vocabulary"}
,{"targetRectangle":{"y":403,
"width":243,
"x":116,
"height":47}
,
"text":"pick most frequent words"}
,{"targetRectangle":{"y":449,
"width":767,
"x":116,
"height":48}
,
"text":"ignore uninformative words from a user-defined short list (ex.: ‘‘ the ’’, ‘‘ a ’’, etc.)"}
,{"targetRectangle":{"y":496,
"width":901,
"x":86,
"height":51}
,
"text":"all words not in the vocabulary will be mapped to a special ‘‘out-of-vocabulary’’ ID"}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":596,
"width":755,
"x":56,
"height":87}
,
"text":"Typical vocabulary sizes will vary between 10 000 \u2028and 250 000"}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s6.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s6.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s6.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s6.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s6.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s6.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":62,
"width":942,
"x":41,
"height":68}
,
"text":"Natural Language Processing"}
,{"targetRectangle":{"y":148,
"width":306,
"x":32,
"height":63}
,
"text":"Topics: vocabulary"}
,{"targetRectangle":{"y":210,
"width":134,
"x":56,
"height":62}
,
"text":"Example:"}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":576,
"width":629,
"x":56,
"height":72}
,
"text":"We will note word IDs with the symbol w"}
,{"targetRectangle":{"y":647,
"width":648,
"x":86,
"height":58}
,
"text":"can think of w as a categorical feature for the original word"}
,{"targetRectangle":{"y":704,
"width":584,
"x":86,
"height":40}
,
"text":"we will sometimes refer to w as a word, for simplicity"}
,{"targetRectangle":{"y":384,
"width":290,
"x":407,
"height":100}
,
"text":""}
,{"targetRectangle":{"y":194.5,
"width":111.1465,
"x":473.7515,
"height":29}
,
"text":"Vocabulary"}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s7.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s7.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s7.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s7.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s7.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s7.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":62,
"width":942,
"x":41,
"height":68}
,
"text":"Natural Language Processing"}
,{"targetRectangle":{"y":148,
"width":410,
"x":32,
"height":63}
,
"text":"Topics: one-hot encoding"}
,{"targetRectangle":{"y":210,
"width":875,
"x":56,
"height":105}
,
"text":"From its word ID, we get a basic representation of a word through the one-hot encoding of the ID"}
,{"targetRectangle":{"y":314,
"width":906,
"x":86,
"height":83}
,
"text":"the one-hot vector of an ID is a vector filled with 0s, except for a 1 at the position associated with the ID"}
,{"targetRectangle":{"y":396,
"width":665,
"x":116,
"height":113}
,
"text":"ex.:  for vocabulary size D=10, the one-hot vector of word ID w=4 is\u2028\u2028                                      e(w) = [ 0 0 0 1 0 0 0 0 0 0 ]"}
,{"targetRectangle":{"y":508,
"width":700,
"x":86,
"height":51}
,
"text":"a one-hot encoding makes no assumption about word similarity"}
,{"targetRectangle":{"y":558,
"width":301,
"x":116,
"height":52}
,
"text":"||e(w) - e(w’)||2 = 0 if w = w’"}
,{"targetRectangle":{"y":609,
"width":302,
"x":116,
"height":53}
,
"text":"||e(w) - e(w’)||2 = 2 if w ≠ w’"}
,{"targetRectangle":{"y":661,
"width":437,
"x":116,
"height":47}
,
"text":"all words are equally different from each other"}
,{"targetRectangle":{"y":707,
"width":694,
"x":86,
"height":33}
,
"text":"this is a natural representation to start with, though a poor one"}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s8.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s8.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s8.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s8.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s8.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s8.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":62,
"width":942,
"x":41,
"height":68}
,
"text":"Natural Language Processing"}
,{"targetRectangle":{"y":148,
"width":410,
"x":32,
"height":63}
,
"text":"Topics: one-hot encoding"}
,{"targetRectangle":{"y":210,
"width":923,
"x":56,
"height":105}
,
"text":"The major problem with the one-hot representation is that it is very high-dimensional"}
,{"targetRectangle":{"y":314,
"width":594,
"x":86,
"height":56}
,
"text":"the dimensionality of e(w) is the size of the vocabulary"}
,{"targetRectangle":{"y":369,
"width":408,
"x":86,
"height":59}
,
"text":"a typical vocabulary size is ≈100 000"}
,{"targetRectangle":{"y":427,
"width":906,
"x":86,
"height":90}
,
"text":"a window of 10 words would correspond to an input vector of at least 1 000 000 units!"}
,{"targetRectangle":{"y":516,
"width":376,
"x":56,
"height":62}
,
"text":"This has 2 consequences:"}
,{"targetRectangle":{"y":577,
"width":280,
"x":86,
"height":51}
,
"text":"vulnerability to overfitting"}
,{"targetRectangle":{"y":627,
"width":779,
"x":116,
"height":47}
,
"text":"millions of inputs means millions of parameters to train in a regular neural network"}
,{"targetRectangle":{"y":673,
"width":290,
"x":86,
"height":51}
,
"text":"computationally expensive"}
,{"targetRectangle":{"y":723,
"width":703,
"x":116,
"height":29}
,
"text":"not all computations can be sparsified (ex.: reconstruction in autoencoder)"}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s9.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s9.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s9.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s9.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s9.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s9.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":54,
"width":840,
"x":92,
"height":82}
,
"text":"Word Representations"}
,{"targetRectangle":{"y":148,
"width":625,
"x":32,
"height":63}
,
"text":"Topics: continuous word representation"}
,{"targetRectangle":{"y":210,
"width":721,
"x":56,
"height":62}
,
"text":"Idea: learn a continuous representation of words"}
,{"targetRectangle":{"y":271,
"width":634,
"x":86,
"height":40}
,
"text":"each word w is associated with a real-valued vector C(w)"}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s10.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s10.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s10.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s10.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s10.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s10.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":54,
"width":840,
"x":92,
"height":82}
,
"text":"Word Representations"}
,{"targetRectangle":{"y":148,
"width":625,
"x":32,
"height":63}
,
"text":"Topics: continuous word representation"}
,{"targetRectangle":{"y":210,
"width":721,
"x":56,
"height":62}
,
"text":"Idea: learn a continuous representation of words"}
,{"targetRectangle":{"y":271,
"width":832,
"x":86,
"height":72}
,
"text":"we would like the distance ||C(w)-C(w’)|| to reflect meaningful similarities between words"}
,{"targetRectangle":{"y":719.5,
"width":353.0566,
"x":334.7964,
"height":49}
,
"text":"(from Blitzer et al. 2004)"}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s11.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s11.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s11.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s11.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s11.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s11.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":54,
"width":840,
"x":92,
"height":82}
,
"text":"Word Representations"}
,{"targetRectangle":{"y":148,
"width":625,
"x":32,
"height":63}
,
"text":"Topics: continuous word representation"}
,{"targetRectangle":{"y":210,
"width":721,
"x":56,
"height":62}
,
"text":"Idea: learn a continuous representation of words"}
,{"targetRectangle":{"y":271,
"width":745,
"x":86,
"height":51}
,
"text":"we can then use these representations as input to a neural network"}
,{"targetRectangle":{"y":321,
"width":777,
"x":86,
"height":163}
,
"text":"to represent a window of 10 words [w1, ... , w10], we concatenate the representations of each word\u2028\u2028                              x = [C(w1)⊤, ... , C(w10)⊤] ⊤"}
,{"targetRectangle":{"y":483,
"width":773,
"x":56,
"height":62}
,
"text":"We learn these representations by gradient descent"}
,{"targetRectangle":{"y":544,
"width":588,
"x":86,
"height":51}
,
"text":"we don’t only update the neural network parameters"}
,{"targetRectangle":{"y":594,
"width":852,
"x":86,
"height":145}
,
"text":"we also update each representation C(w) in the input x with a gradient step\u2028\u2028\u2028where l  is the loss function optimized by the neural network"}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s12.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s12.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s12.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s12.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s12.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s12.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":54,
"width":840,
"x":92,
"height":82}
,
"text":"Word Representations"}
,{"targetRectangle":{"y":148,
"width":727,
"x":32,
"height":63}
,
"text":"Topics: word representations as a lookup table"}
,{"targetRectangle":{"y":210,
"width":913,
"x":56,
"height":75}
,
"text":"Let C be a matrix whose rows are the representations C(w)"}
,{"targetRectangle":{"y":284,
"width":648,
"x":86,
"height":60}
,
"text":"obtaining C(w) corresponds to the multiplication e(w)⊤ C"}
,{"targetRectangle":{"y":343,
"width":618,
"x":86,
"height":58}
,
"text":"in words, we are projecting e(w) onto the columns of C"}
,{"targetRectangle":{"y":400,
"width":725,
"x":116,
"height":58}
,
"text":"this is a reduction of the dimensionality of the one-hot representations e(w)"}
,{"targetRectangle":{"y":457,
"width":858,
"x":86,
"height":51}
,
"text":"this is a continuous transformation, through which we can propagate gradients"}
,{"targetRectangle":{"y":144,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":568,
"width":925,
"x":56,
"height":116}
,
"text":"In practice, we implement C(w) with a lookup table, not with a multiplication"}
,{"targetRectangle":{"y":683,
"width":564,
"x":86,
"height":40}
,
"text":"C(w) returns an array pointing to the wth row of C"}
]
}
,{"automaticPlay":false,
"hyperlinks":[]
,
"eventInitialStates":[{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s13.b",
"hidden":0}
,{"opacity":1,
"affineTransform":[1,0,0,1,0,0]
,
"texture":"s13.a",
"hidden":0}
]
,
"eventAnimations":[{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":1}
,
"action":"hidden",
"texture":"s13.a",
"to":{"scalar":1}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s13.a"]
}
,{"effect":"none",
"actions":[{"beginTime":0,
"from":{"scalar":0}
,
"action":"hidden",
"texture":"s13.b",
"to":{"scalar":0}
,
"timingFunction":"linear",
"duration":0.001}
]
,
"duration":0.001,
"animationType":"transition",
"beginTime":0,
"textures":["s13.b"]
}
]
,
"textRegions":[{"targetRectangle":{"y":75,
"width":460,
"x":282,
"height":82}
,
"text":"Conclusion"}
,{"targetRectangle":{"y":183,
"width":751,
"x":56,
"height":61}
,
"text":"We looked at the preprocessing steps of text data"}
,{"targetRectangle":{"y":244,
"width":675,
"x":86,
"height":55}
,
"text":"tokenization, lemmatization and vocabulary extraction"}
,{"targetRectangle":{"y":179,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":360,
"width":758,
"x":56,
"height":61}
,
"text":"We discussed the challenge that text data presents"}
,{"targetRectangle":{"y":421,
"width":362,
"x":86,
"height":55}
,
"text":"data is very high-dimensional"}
,{"targetRectangle":{"y":476,
"width":691,
"x":86,
"height":55}
,
"text":"requires large quantity of data to learn in such a setting"}
,{"targetRectangle":{"y":179,
"width":0,
"x":28,
"height":0}
,
"text":""}
,{"targetRectangle":{"y":592,
"width":833,
"x":56,
"height":61}
,
"text":"We looked at the idea of learning word representations"}
,{"targetRectangle":{"y":653,
"width":910,
"x":86,
"height":74}
,
"text":"these representations are trained within a neural network, with gradient descent"}
]
}
]
,
"loopSlideshow":0,
"showMode":0,
"majorVersion":0,
"notes":{}
,
"creator":"Apple Keynote 5.2",
"author":"",
"comment":"",
"pageCount":13,
"scalefactor480":0.3310547,
"slideCount":13}
