<!DOCTYPE html >
<html >
  <head>
    <title>Hugo Larochelle</title>
    <meta http-equiv="content-type" content="text/html; charset=iso-8859-1" />
    <link rel="stylesheet"
          href="http://fonts.googleapis.com/css?family=Droid+Sans:regular,bold,italic"
          type="text/css" />
    <link rel="stylesheet" href="css/2.css" type="text/css" media="screen,projection" />

  </head>
  
  <body>

    <div id="wrapper">
      <div id="innerwrapper">

	<div id="header">
      <div id="header-text">
	  Hugo Larochelle
	  <!-- <h1 id="header-right"></h1>-->
	    <ul id="nav">
	      
	      <li><a href="index_en.html" accesskey="H" class="active"><em>H</em>ome</a></li>
	      
	      <li><a href="publications_en.html" accesskey="p"><em>P</em>ublications</a></li>

	      <li><a href="university_en.html" accesskey="u"><em>U</em>niversity</a></li>

	      <li><a href="links_en.html" accesskey="l"><em>L</em>inks</a></li>

	    </ul>
        </div>
	  </div>
	  
	  <div id="sidebar">
	    <h2>Research projects</h2>

	    <table id="nav" cellpadding="0" cellspacing="10" >
	      <tr><td  class="active"><a href="projects_attention.html">Attention-based computer vision</a></td></tr>
	      <tr><td><a href="projects_deep_learning.html">Deep learning</a></td></tr>
	      <tr><td><a href="projects_classrbm.html">Restricted Boltzmann machines for classification</a></td></tr>
	      <tr><td><a href="projects_struct_output.html">Learning algorithms for structured output prediction</a></td></tr>
	      <tr><td><a href="projects_nade.html">Neural autoregressive models</a></td></tr>
	    </table>

	  </div>
	  
	  <!--
	  <div id="sidebarright">
	  </div>
	  -->

	  <div id="contentnorightbar">
	    <h2> Attention-based computer vision </h2>
	    
	    A fundamental aspect of human vision is that of attention,
	    i.e. the process by which we focus the computational
	    resources of our brain's visual system to specific regions
	    of the visual field. Based on the nature of the task to
	    solve, we can then ignore irrelevant visual information by
	    intelligently exploring the visual field. Maliciously exploiting this
	    aspect can even yield 
	    <a href="http://www.youtube.com/watch?v=vJG698U2Mvo">surprising
	    results</a>...
	    <br><br>

	    Yet few computer vision systems incorporate this
	    notion. They instead tend to systematically explore all
	    of the visual field, sometimes at a resolution low enough
	    to make this exploration tractable. 
	    I'm hence interested in developing new vision systems that
	    do rely attention mechanisms in order to allocate its
	    computational power intelligently.<br><br>

	    In <a href="publications/nips_eyebm.pdf">Learning
	    to combine foveal glimpses with a third-order Boltzmann
	    machine</a>,
	    <a href="http://www.cs.toronto.edu/~hinton/">Geoffrey
	    Hinton</a> and I developed learning algorithms for a
	    Boltzmann machine capable of integrating the result of
	    several fixations generated by a simulated multi-resolution
	    retina. This system can be used to classify images based
	    on the information contained in a limited number of
	    fixations. <br><br>

	    <center>
	    <iframe width="425" height="349" src="http://www.youtube.com/embed/Pl6Z-ZAldSY?hl=fr&fs=1" frameborder="0" allowfullscreen></iframe>
	    </center><br>

	    When applied to the problem of recognizing
	    facial expressions, this system is even able to
	    learn to focus its attention on informative facial
	    features, mainly the mouth and eyes, and ignore
	    irrelevant features such as the nose or hair (see video above).<br><br>
	    
	    Following this work, in a collaboration
	    with <a href="http://www.lorisbazzani.info/">Loris
	    Bazzani</a>, <a href="http://www.cs.ubc.ca/~nando/">Nando
	    de
	    Freitas</a>, <a href="http://profs.sci.univr.it/~swan/">Vittorio
	    Murino</a>
	    and <a href="http://www.joanneting.net/">Jo-Anne Ting</a>,
	    a similar Boltzmann machine was developed for an object
	    recognition and tracking system, described
	    in <a href="publications/rbmTracking.pdf">
	    Learning Attentional Policies for Tracking and Recognition
	    in Video with Deep Networks</a>. Loris put
	    together <a href="http://www.youtube.com/watch?v=e14xHDS-Cnk&feature=youtu.be">several
	    videos</a> of the system in action, demonstrating its
	    ability to track faces and hockey players:<br><br>
	    <center>
	      <iframe width="425" height="349" src="http://www.youtube.com/embed/e14xHDS-Cnk" frameborder="0" allowfullscreen></iframe>
	    </center><br>

	    <h3>References</h3>
	    <br>
	    <ul>
	      <li> <b> Learning Attentional Policies for Tracking and Recognition in Video with Deep Networks [<a href="publications/rbmTracking.pdf" target=_top>pdf</a>] [<a href="http://techtalks.tv/talks/54324/">talk</a>] [<a href="http://www.youtube.com/watch?v=e14xHDS-Cnk&feature=youtu.be">youtube</a>]</b><br>
		Loris Bazzani, Nando de Freitas, Hugo Larochelle, Vittorio Murino and Jo-Anne Ting,<br>
		<i> International Conference on Machine Learning proceedings</i>, 2011<br><br>

	      <li> <b>Learning to combine foveal glimpses with a third-order Boltzmann machine [<a href="publications/nips_eyebm.pdf" target=_top>pdf</a>] [<a href="publications/nips_eyebm_supp.pdf" target=_top>supp</a>] [<a href="http://videolectures.net/nips2010_larochelle_lcf/">talk</a>] [<a href="">faces video</a>] </b><br>
		Hugo Larochelle and Geoffrey Hinton,<br>
		<i>Advances in Neural Information Processing Systems 23</i>, 2010<br><br>

	    </ul>


	  </div>
	  
	  <div id="footer">
	  </div>
	  
	</div>
      </div>


    </body>
  </html>
